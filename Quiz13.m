1번.
"Perceptron 알고리즘으로 분류를 할 때 분류의 기준이 되는 decision boundary는 
w에 수직이다."라는 진술이 맞는지 확인하고, 맞다면 O, 틀리다면 𝑋 선택하는 문제

-> 결정 경계는 벡터w에 수직임.
( w^T * x = 0에서 w는 결정 경계와 직교하며, 방향은 결정 경계의 한쪽 클래스에 대한 정보 제공)
-> Perceptron의 결정 경계는 데이터를 선형적으로 나누는 초평면이며, 이 초평면은 w에 의해 정의됨.
-> w는 결정 경계와 직각을 이루며, w의 방향은 분류된 데이터가 어느 쪽 클래스에 속하는지 나타냄.

==========================================================================================

2번.
"Perceptron 알고리즘의 w에 대한 설명 중 옳지 않은 것을 고르시오."

- Perceptron 알고리즘의 핵심은 가중치w를 학습 데이터에 따라 반복(iteration)적으로
업데이트하며, 예측 결과가 실제 레이블과 다를 경우메만 업데이트를 수행.

1) iteration하면서 update된다.
- Perceptron 알고리즘은 반복을 통해 가중치 w를 업데이트. (맞는 설명)

2) sign(w^t * xn)이 yn과 다를 때 update된다. (맞는 설명)
- Perceptron의 가중치 업데이트 조건은 예측 값과 실제 레이블이 다른 경우

3) sign(w^t * xn)이 yn과 같을 때 update된다. (틀린 설명)
-> 예측이 맞는 경우 가중치w를 수정하지 않음.

===============================================================================================

3번.
"회귀와 분류 알고리즘에 대한 설명 중 옳지 않은 것을 고르시오."

1) 회귀는 지도학습 알고리즘이다.(O)
- 회귀(regression)는 지도학습(supervised learning)에 속하며, 입력값 x와
연속적인 출력 값 y 사이의 관계를 학습하는 알고리즘이다. 

2) 분류는 비지도학습 알고리즘이다. (X)
- 분류(classification)은 지도학습에 속함. 
분류 알고리즘은 x와 이산적인 레이블(클래스)을 학습하는 방식.
비지도학습은 레이블 없이 데이터의 구조를 학습하는 군집화(clustering)등이 해당

3) 회귀는 입력 값x에 대한 출력 값 y가 연속적일때 사용할 수 있다. (O)
- 회귀는 연속적인 값을 예측하기 위한 알고리즘임.

4) 분류는 입력 값 x에 대한 출력 값 y가 연속적일 때 사용할 수 없다.(O)
- 분류는 출력 값이 이산적인 값을 가질 때 사용하는 알고리즘.
(연속적인 값을 다루지 않음.)

추가설명 :
회귀와 분류 모두 지도학습 알고리즘에 속함.
회귀 (연속적인 출력 값을 학습)
분류 (이산적인 출력 값을 학습)

================================================================================================

4번.
SVM(Support Vector Machine)에 대한 설명 중 옳은 것을 고르시오.

1) w는 decision boundary에 평행하다. (X)
- SVM에서 W는 decision boundary를 정의하는 벡터임.
이는 decision boundary에 수직이지, 평행하지 않음.

2) w0는 직선을 유일하게 결정하기 위해 필요하다. (O)
- W0는 decision boundary의 bias향으로, 직선을 정확히 정의하기 위해 필요
즉, w0는 decision boundary의 위치를 조정하는 역할.

3) 1/w0은 g(x)=1 과 g(x)= -1까지의 거리이다.(X)
- SVM에서 g(x) = w^t *x + w0는 결정 함수이며, 1/w가 결정 경계와 서포트 벡터 사이의
거리(마진)을 정의함. w0는 거리와 직접적인 관계가 없다.

4) SVM은 최적화의 개념이 포함되지 않은 알고리즘이다. (X)
- SVM은 마진을 최대화하기 위한 최적화 문제를 품. 따라서 최적화 개념이 포함된 알고리즘

추가설명
1. SVM의 목표는 결정 경계와 서포트 벡터 사이의 마진을 최대화 하는 것
2. 최적화를 통해 W와 W0를 계산하여 결정 경계를 학습함.

===================================================================================================

5번.
SVM과 perceptron은 둘 다 decision boundary에서 데이터 포인트까지의 거리에 대한 정보를 고려한 알고리즘이다."라는 진술이 맞는지 확인

-Perceptron
1) Perceptron 알고리즘은 단순히 데이터가 올바르게 분류되었는지 여부만을 고려
2) 즉, 데이터 포인트가 decision boundary에서 얼마나 멀리 떨어져 있는지는 고려하지 않음.
3) 잘못 분류된 데이터가 있을 때만 가중치 w와 w0를 업데이트함

-SVM(support vector machine)
1) SVM은 데이터 포인트와 결정 경계 사이의 거리를 고려
2) 서포트 벡터와 결정 경계 사이의 마진을 최대화하려고 한다.
3) SVM은 거리 정보를 적극적으로 사용

==================================================================================================

6번.
"SVM은 outlier가 있더라도 수렴하는 알고리즘이다."라는 진술이 맞는지 확인
SVM(support vector machine) : SVM은 마진을 최대화하면서 데이터를 분류하는 알고리즘
1) Hard Margin SVM : 
-데이터가 결정 경계와 정확히 분리될 수 있다고 가정.
-모든 데이터가 완벽히 분류되도록 학습하므로, outlier에 매우 민감
2) soft Margin SVM :
- 실세계 데이터에는 노이즈나 outlier가 존재할 가능성을 고려
- 일부 데이터가 결정 경계를 벗어나더라도 수용할 수 있도록 설계
- slack변수를 도입하여 노이즈를 허용하면서도 최적화 문제를 해결
3) Outlier와 SVM :
- Hard Margin SVM은 outlier가 있을때 수렴하지 않거나 비효율적일 수 있음
- Soft Margin SVM은 outlier가 있어도 수렴 간능하며, 일반적으로 실세계 문제에 적합

즉, soft margin svm을 전제로할때 맞는 설명임.

================================================================================================

7번.
"Slack variable은 decision boundary에 가장 가까운 outlier 하나이다."라는 진술이 맞는지 확인

1) Slack variable은 Soft Margin SVM에 사용됨.
결정 경계에 가까운 여러데이터포인트(outlier를 포함) 또는 경계를 침범한 데이터에 대해 정의
- 가장 가까운 하나만 slack variable로 정의되지 않음

즉, 틀림

===================================================================================================

8번.
"Slack variable은 항상 양의 정수, 음의 정수, 또는 0이 될 수 있다."라는 진술이 맞는지 확인

- Slack variable은 음수가 될 수 없음.
- slack variable은 연속적인 값을 가질 수 있으므로, 정수로 제한되지 않음

즉, 틀림

=====================================================================================

9번.
SVM은 linear classifier이지만 kernel method를 이용하여 비선형적으로 분포한 데이터를 분류할 수 있다."라는 진술이 맞는지 확인

- 기본적으로 svm은 linear classifier임.
- SVM은 본질적으로 선형 분류기지만, 커널 방법을 통해 비선형 분포의 데이터를 처리할 수 있음

즉, 맞는 설명

=========================================================================================================

10번.
sign이 들어감

