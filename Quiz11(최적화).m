# 1번
1. Under-determined linear system에서는 미지수의 수가 constraint보다 많아 해가 많이 존재한다. (O)
2. 𝐴가 m×n 행렬일 때 m>n이면 under-determined linear system이다. (X)
3. Over-determined linear system은 fat한 𝐴행렬을 가진다. (X)
4. A가 정사각행렬이면 항상 well-determined linear system이다. (X)

# =====================================================================================================================

# 2번
1. Well-determined system: (X)
2. Over-determined system: (O)
3. Under-determined system: (X)
4. 이 중에 정답이 없다: (X)

# =====================================================================================================================

# 3번
1. A가 Fat 행렬이면 이 식에 대한 많은 솔루션이 존재한다. (O)
2. 위 식의 많은 해 중 원점과의 거리가 최소인 점이 최적화 문제의 정답이다. (O)
3. 위와 같은 최적화 문제는 control에 주로 응용된다. (O)
4. 위의 식은 원점을 지나는 직선이다. (X)

# =====================================================================================================================

# 4번

최적화 문제의 기본 요소:

ㄱ 목적함수 (Objective function):
최적화 문제의 핵심으로, 최댓값이나 최솟값을 찾고자 하는 대상임.
예: 비용을 최소화하거나 효율을 최대화.

ㄴ 오차 (Error):
최적화 문제의 필수 요소는 아님.
오차는 데이터 모델링이나 회귀 분석에서 잔차(residual)로 사용될 수 있으나, 최적화 문제의 기본 구성 요소로는 포함되지 않음.

ㄷ 제약조건 (Constraints):
최적화 문제에서 필수 요소
변수들이 따라야 할 조건(제약)을 정의하며, 이를 만족시키면서 최적화를 수행함.
예: 𝐴𝑥≤𝑏, Ax≤b, 𝑥≥0

변수 (Decision variable):
최적화 문제의 또 다른 필수 요소
결정 변수는 최적화의 결과로 결정되는 값이며, 목적함수를 최적화하고 제약조건을 만족시키기 위해 사용됨

ㄱ, ㄷ ,ㄹ 

# =====================================================================================================================

# 5번 패스

# =====================================================================================================================

# 6번
1. objective function이 non-convex function인 경우 local solution은 항상 global solution이 된다. (X)
2. 제약조건이 있는 경우(constrained)와 없는 경우(unconstrained)가 있다. (O)
3. convex optimization 문제를 해결하기 위한 module로 cvxpy가 있다. (O)
4. modeling 단계와 solving 단계를 분리하기 위하여 등가변환을 한다. (O)

# =====================================================================================================================

# 7번 패스

# =====================================================================================================================

# 8번 x ← x−α∇xf(x)는 Gradient Descent 알고리즘을 나타냄. 이 알고리즘에 대한 설명 중 옳지 않은 것을 고르라는 문제

1. iterative method이다.
Gradient Descent는 초기값 𝑥0를 설정한 후, 반복적으로 값을 업데이트하는 방식이므로 iterative method가 맞음.
⇒ 옳은 설명

2. 기울기(∇𝑥𝑓(𝑥))는 기존 x에서 update될 x로 이동하는 방향성을 결정한다.
기울기는 현재 위치에서의 변화율을 나타내며, 이 기울기를 따라 이동.
정확히는 기울기의 반대방향(-∇𝑥𝑓(𝑥))으로 이동하여 f(x0)값을 최소화하려는 알고리즘임.
-> 옳은 설명

3. alpha는 atep size를 결정한다.
alpha는 학습률(learning rate) 또는 step size로, 한 번의 업데이트에서 이동하는 크기를 결정한다.
-> 옳은 설명

4. Gradient Descent method는 모든 조건에서 무조건 최적해로 수렴하는 알고리즘
초기값, 함수의 형턔(예: 비볼록 함수), 학습률 alpha 등에 따라 최적해에 도달하지 못할 수 있음. 틀림.
-> 틀림

요약
Gradient Descent는 매우 널리 사용되는 최적화 알고리즘이지만. 항상 최적해로 수렴하는 것은 아님.
초기값, 함수의 볼록성(convexity), 학습률 설정 등에 따라 지역 최적해(local minimum)에 머물거나 수렴하지 않을 가능성도 있음 -> 따라서 "모든 조건에서 무조건 최적해로 수렴한다"는 x

# =====================================================================================================================

# 9번. 다음 중 Convex function이 아닌 것을 고르시오.

Convex function은 다음 조건을 만족해야 함.
2차 미분이 항상 0 이상 (즉, f''(x)≥0)이면 convex임. 또는, 그래프가 아래로 볼록한 형태를 가지면 convex로 간주

1. f(x) = x^2 
-> f''(x) = 2니까  convex임 (O)

2. f(x) = x^3
-> f''(x) = 6x이니까 convex가 아님. x가 음수일 때 0보다 낮으니 (X)

3. |x|^0.5(=루트)
-> convex (O)

4. f(x) = x^4 
-> f''(x) = 12x^2 이니까 convex임 (O)

# =====================================================================================================================

# 10번. f(x1,x2) = (x_1)^2 + 2x_2^2 + 4x_1 + 3 에 대하여 Learning rate를 0.1로 설정하였다.
초기점이 x1 = 1, 2 =1일때 Gradient descent 알고리즘 을 통해 1번의 iteration을 시행한 후의 x1과 x2의 값으로 올바른 것은?

Gradient descent 알고리즘 
xi <- xi - a(편미분)

1단계) 각 변수에 대한 편미분 계산
x_1 편미분 : 2x_1 +4 -> 6
x_2 편미분 : 4x_2 -> 4

2단계) 알고리즘 식 적용
1) x_1
x_1 : x_1 - a(x_1편미분)
= x_1 <- 1 - 0.1(6)= 1 - 0.6 = 0.4

2) x_2
= x_2 <- x_2 - a(x_2편미분)
= x_2 <- 1 - 0.1(4) = 1 - 0.4 = 0.6